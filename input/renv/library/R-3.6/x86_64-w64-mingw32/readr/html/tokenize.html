<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Tokenize a file/string.</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for tokenize {readr}"><tr><td>tokenize {readr}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Tokenize a file/string.</h2>

<h3>Description</h3>

<p>Turns input into a character vector. Usually the tokenization is done purely
in C++, and never exposed to R (because that requires a copy). This function
is useful for testing, or when a file doesn't parse correctly and you want
to see the underlying tokens.
</p>


<h3>Usage</h3>

<pre>
tokenize(file, tokenizer = tokenizer_csv(), skip = 0, n_max = -1L)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>file</code></td>
<td>
<p>Either a path to a file, a connection, or literal data
(either a single string or a raw vector).
</p>
<p>Files ending in <code>.gz</code>, <code>.bz2</code>, <code>.xz</code>, or <code>.zip</code> will
be automatically uncompressed. Files starting with <code style="white-space: pre;">http://</code>,
<code style="white-space: pre;">https://</code>, <code style="white-space: pre;">ftp://</code>, or <code style="white-space: pre;">ftps://</code> will be automatically
downloaded. Remote gz files can also be automatically downloaded and
decompressed.
</p>
<p>Literal data is most useful for examples and tests. To be recognised as
literal data, the input must be either wrapped with <code>I()</code>, be a string
containing at least one new line, or be a vector containing at least one
string with a new line.
</p>
<p>Using a value of <code><a href="clipboard.html">clipboard()</a></code> will read from the system clipboard.</p>
</td></tr>
<tr valign="top"><td><code>tokenizer</code></td>
<td>
<p>A tokenizer specification.</p>
</td></tr>
<tr valign="top"><td><code>skip</code></td>
<td>
<p>Number of lines to skip before reading data.</p>
</td></tr>
<tr valign="top"><td><code>n_max</code></td>
<td>
<p>Optionally, maximum number of rows to tokenize.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre>
tokenize("1,2\n3,4,5\n\n6")

# Only tokenize first two lines
tokenize("1,2\n3,4,5\n\n6", n = 2)
</pre>

<hr /><div style="text-align: center;">[Package <em>readr</em> version 2.1.2 <a href="00Index.html">Index</a>]</div>
</body></html>
